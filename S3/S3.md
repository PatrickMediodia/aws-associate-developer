buckets (kind of like directories)
- bucket names must be globally unique
- buckets are created per region
	- it may look like a global service but buckets are created in a specific region

objects
- data are stored as objects

Key
- `bucket name + prefix + object name`
- bucket name = `s3://{bucket_name}`
- prefix = `/directory1/directory2`
- object name = `file_name.txt`

Security
- User Based
	- IAM Policies
- Resource Based
	- Bucket Policies
	- bucket wide rules
		- the most common way to control bucket access
		- allows cross account
		- used to make s3 bucket public
	- Object Access Control List (OACL)
		- finer grained
		- can be disabled
	- Bucket Access Control List (BUCL)
		- can be disabled

- Users can access S3 resources if the IAM permissions allows it OR the bucket resource policily AND there is not explicity deny
- Can be encrypted using access keys

![[Pasted image 20240421121606.png]]

**Bucket Policy**
![[Pasted image 20240421121647.png]]

**IAM Users**
![[Pasted image 20240421122034.png]]

**IAM Roles**
![[Pasted image 20240421122104.png]]

**Cross Account Access**
![[Pasted image 20240421122145.png]]

**Block Public Access**
![[Pasted image 20240421122844.png]]
- can be set at the account level

Versioning
- enabled at the bucket level
- objects not versions before turning on versioning will have a version of null
- even if you turn off versioning, it will still save the past versions of the file
- deleted version files are not actually deleted, it is just put with a delete marker

Replication
- source and destination bucket versioning must be enabled
- copying is asynchronous
- CRR (Cross Region Replication)
- SRR (Same Region Replication)
![[Pasted image 20240421145537.png]]

![[Pasted image 20240421145641.png]]
- normally it would only replicate the new objects that will be uploaded to the bucket, but you can replicate existing objects and AWS will ask you for this
- by default, delete markers are not replicated

**S3 Storage Classes**
![[Pasted image 20240421151930.png]]
![[Pasted image 20240421152044.png]] 

S3 Standard
- used for frequently accessed data
- low latency and high throughput
- used for normal situations
- 99.99% available

S3 Infrequent Access
- less accessed, but required rapid access when needed
- lower cost than s3 standard
- 99.9% available
- disaster recovery, backups

S3 One Zone Infrequent Access
- data is lost if AZ is destroyed
- 99.5% availability
- secondary copies of backups or data you can recreate

S3 Glacier (Low cost)
- meant for archiving and backup
- price for storage and retrieval cost

- Instant
	- ms second retirival
	- great for data accessed once a quarter
	- minimum storage duration of 90 days
	- backup but need to access in ms

- Flexible Retrieval
	- Expidited - 1 to 5 minutes
	- Standard - 3 to 5 hours
	- Bulk - 5 to 12 hours (free)
	- minimum storage duration of 90 days
	- willing to wait before you retrieve

 - Deep Archive
	 - long term storage
	 - standard - 12 hours
	 - build - 48 hours
	 - lowest cost
	 - minimum storage duration of 180 days

S3 Intelligent Tiering
- small monthly monitoring and auto tiering fee
- moves objects automatically between access storage tiers based on usage
![[Pasted image 20240421153233.png]]

![[Pasted image 20240421153213.png]]

